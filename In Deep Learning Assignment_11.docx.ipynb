{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5764ae1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. Write the Python code to implement a single neuron.\n",
    "\n",
    "Ans-\n",
    "\n",
    "Certainly! In deep learning, a single neuron (also known as a perceptron) can be represented as a simple linear\n",
    "function followed by an activation function. Here's how you can implement a single neuron using Python:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "# Define the single neuron function\n",
    "def single_neuron(input_data, weights, bias):\n",
    "    # Calculate weighted sum and add bias\n",
    "    weighted_sum = np.dot(input_data, weights) + bias\n",
    "    \n",
    "    # Apply activation function (for example, sigmoid)\n",
    "    output = 1 / (1 + np.exp(-weighted_sum))\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Example usage\n",
    "input_data = np.array([2, 3])  # Example input data\n",
    "weights = np.array([0.5, -0.8])  # Example weights\n",
    "bias = 0.2  # Example bias\n",
    "\n",
    "# Calculate output of the single neuron\n",
    "output = single_neuron(input_data, weights, bias)\n",
    "\n",
    "# Print the output\n",
    "print(\"Output of the single neuron:\", output)\n",
    "```\n",
    "\n",
    "In this code, the `input_data` represents the input features, `weights` represent the weights of the neuron's connections,\n",
    "and `bias` is the bias term. The `single_neuron` function calculates the weighted sum of inputs, adds the bias,\n",
    "and applies the sigmoid activation function to produce the output of the neuron. You can modify the activation \n",
    "function as per your requirements.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "2. Write the Python code to implement ReLU.\n",
    "\n",
    "\n",
    "Ans-\n",
    "\n",
    "Certainly! ReLU (Rectified Linear Unit) is a popular activation function used in deep learning. \n",
    "Here's how you can implement ReLU using Python:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "# Define the ReLU activation function\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "# Example usage\n",
    "input_data = np.array([-1, 0, 2, 3, -2.5])\n",
    "\n",
    "# Apply ReLU activation function to the input data\n",
    "output = relu(input_data)\n",
    "\n",
    "# Print the output\n",
    "print(\"Output after applying ReLU:\", output)\n",
    "```\n",
    "\n",
    "In this code, the `relu` function takes an input `x` and applies the ReLU activation function element-wise,\n",
    "replacing any negative values with zero. The `np.maximum(0, x)` function ensures that only values greater than\n",
    "or equal to zero are retained.\n",
    "\n",
    "You can pass different input values in the `input_data` array to observe the output after applying the ReLU\n",
    "activation function.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "3. Write the Python code for a dense layer in terms of matrix multiplication.\n",
    "\n",
    "\n",
    "Ans-\n",
    "\n",
    "\n",
    "In deep learning, a dense layer (also known as a fully connected layer) performs a matrix multiplication followed\n",
    "by a bias addition and an activation function. Here's how you can implement a dense layer using matrix\n",
    "multiplication in Python:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "# Define the dense layer function using matrix multiplication\n",
    "def dense_layer(input_data, weights, bias, activation_function=None):\n",
    "    # Perform matrix multiplication and add bias\n",
    "    weighted_sum = np.dot(input_data, weights) + bias\n",
    "    \n",
    "    # Apply activation function if provided\n",
    "    if activation_function is not None:\n",
    "        output = activation_function(weighted_sum)\n",
    "    else:\n",
    "        output = weighted_sum\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Example usage\n",
    "input_data = np.array([1, 2, 3])  # Example input data\n",
    "weights = np.array([[0.1, 0.2, 0.3], [0.4, 0.5, 0.6]])  # Example weights for two neurons\n",
    "bias = np.array([0.7, 0.8])  # Example bias for two neurons\n",
    "\n",
    "# Apply dense layer operation with ReLU activation function\n",
    "output = dense_layer(input_data, weights, bias, activation_function=np.maximum(0,))\n",
    "\n",
    "# Print the output\n",
    "print(\"Output of the dense layer:\", output)\n",
    "```\n",
    "\n",
    "In this code, `input_data` represents the input features, `weights` represents the weights connecting \n",
    "the input to the neurons in the dense layer, and `bias` represents the bias terms for each neuron. \n",
    "The `np.dot(input_data, weights)` performs the matrix multiplication, and the bias is added element-wise.\n",
    "The `activation_function` parameter allows you to specify an activation function (in this case, ReLU) to\n",
    "be applied after the matrix multiplication and bias addition.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "4. Write the Python code for a dense layer in plain Python (that is, with list comprehensions\n",
    "and functionality built into Python).\n",
    "\n",
    "\n",
    "\n",
    "Ans-\n",
    "\n",
    "Certainly! Here's how you can implement a dense layer in plain Python using list comprehensions for matrix\n",
    "multiplication and bias addition:\n",
    "\n",
    "```python\n",
    "# Define the dense layer function using list comprehensions\n",
    "def dense_layer(input_data, weights, bias, activation_function=None):\n",
    "    # Perform matrix multiplication and add bias using list comprehensions\n",
    "    weighted_sum = [sum(i * j for i, j in zip(input_data, w)) + b for w, b in zip(weights, bias)]\n",
    "    \n",
    "    # Apply activation function if provided\n",
    "    if activation_function is not None:\n",
    "        output = [activation_function(ws) for ws in weighted_sum]\n",
    "    else:\n",
    "        output = weighted_sum\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Example usage\n",
    "input_data = [1, 2, 3]  # Example input data\n",
    "weights = [[0.1, 0.2, 0.3], [0.4, 0.5, 0.6]]  # Example weights for two neurons\n",
    "bias = [0.7, 0.8]  # Example bias for two neurons\n",
    "\n",
    "# Apply dense layer operation with ReLU activation function\n",
    "output = dense_layer(input_data, weights, bias, activation_function=lambda x: max(0, x))\n",
    "\n",
    "# Print the output\n",
    "print(\"Output of the dense layer:\", output)\n",
    "```\n",
    "\n",
    "In this code, `input_data` is a Python list representing the input features, `weights` is a list of lists\n",
    "representing the weights connecting the input to the neurons in the dense layer, and `bias` is a list \n",
    "representing the bias terms for each neuron. The list comprehensions are used for matrix multiplication \n",
    "and bias addition. The `activation_function` parameter allows you to specify an activation function \n",
    "(in this case, ReLU) to be applied after the matrix multiplication and bias addition.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "5. What is the “hidden size” of a layer?\n",
    "\n",
    "\n",
    "Ans-\n",
    "\n",
    "In deep learning, the \"hidden size\" of a layer refers to the number of neurons or units in that layer.\n",
    "It represents the dimensionality of the space in which the neural network can operate and learn to\n",
    "represent complex patterns in the input data.\n",
    "\n",
    "For example, in a neural network architecture, you might have an input layer with a certain number\n",
    "of input features (input size), one or more hidden layers, and an output layer. Each hidden layer\n",
    "consists of a specific number of neurons, which is its hidden size. The hidden size is a hyperparameter\n",
    "that you can adjust when designing your neural network.\n",
    "\n",
    "The choice of the hidden size is crucial and can affect the capacity of the network to learn from the data.\n",
    "Too few neurons might result in the network being unable to capture complex patterns in the data (underfitting), \n",
    "while too many neurons can lead to the model memorizing the training data instead of generalizing well to unseen\n",
    "data (overfitting). It often requires experimentation and tuning to find an appropriate hidden size for a specific task.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "6. What does the t method do in PyTorch?\n",
    "\n",
    "\n",
    "Ans-\n",
    "\n",
    "In PyTorch, the `.t()` method is used to transpose a tensor. Transposing a tensor means exchanging its rows and,\n",
    "columns. For a 2D tensor (matrix), the `.t()` method will swap its rows and columns.\n",
    "\n",
    "Here's an example of how you can use the `.t()` method in PyTorch:\n",
    "\n",
    "```python\n",
    "import torch\n",
    "\n",
    "# Create a 2D tensor (matrix)\n",
    "tensor = torch.tensor([[1, 2, 3],\n",
    "                      [4, 5, 6]])\n",
    "\n",
    "# Transpose the tensor\n",
    "transposed_tensor = tensor.t()\n",
    "\n",
    "# Print the original and transposed tensors\n",
    "print(\"Original Tensor:\")\n",
    "print(tensor)\n",
    "print(\"Transposed Tensor:\")\n",
    "print(transposed_tensor)\n",
    "```\n",
    "\n",
    "Output:\n",
    "```\n",
    "Original Tensor:\n",
    "tensor([[1, 2, 3],\n",
    "        [4, 5, 6]])\n",
    "Transposed Tensor:\n",
    "tensor([[1, 4],\n",
    "        [2, 5],\n",
    "        [3, 6]])\n",
    "```\n",
    "\n",
    "In this example, the `.t()` method transposes the original 2x3 tensor into a 3x2 tensor by swapping its rows and columns.\n",
    "\n",
    "Note: The `.t()` method works only for 2D tensors. For tensors with more than two dimensions, you can use the ,\n",
    "    `torch.transpose()` function to specify the dimensions along which you want to transpose the tensor.\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "7. Why is matrix multiplication written in plain Python very slow?\n",
    "\n",
    "\n",
    "Ans-\n",
    "\n",
    "Matrix multiplication written in plain Python using nested loops can be very slow for several reasons:\n",
    "\n",
    "1. **Dynamic Typing:** Python is a dynamically typed language, which means that variable types are determined at runtime. \n",
    "    This dynamic typing results in additional overhead for type checking and conversion, making operations slower\n",
    "    compared to statically typed languages like C or Fortran.\n",
    "\n",
    "2. **Interpreted Language:** Python is an interpreted language, and each operation is executed line by line by the\n",
    "    Python interpreter. Interpreted languages are generally slower than compiled languages because there's an\n",
    "    additional layer of interpretation and translation of code to machine instructions.\n",
    "\n",
    "3. **Lack of Low-Level Optimization:** Python does not optimize low-level operations like C or assembly languages do.\n",
    "    Optimized libraries and compilers can take advantage of specific processor instructions and memory access patterns,\n",
    "    leading to faster matrix operations.\n",
    "\n",
    "4. **No Parallelization:** Plain Python code does not automatically leverage multiple cores or processors, meaning\n",
    "    that matrix multiplication won't be parallelized unless explicitly implemented, unlike some optimized libraries\n",
    "    that can utilize parallel processing for speedup.\n",
    "\n",
    "5. **Inefficient Memory Access:** Python lists are not optimized for numerical computations. Accessing elements \n",
    "    in Python lists involves additional checks and overhead, which can slow down matrix multiplication significantly, \n",
    "    especially for large matrices.\n",
    "\n",
    "For efficient matrix operations in Python, it's recommended to use optimized libraries such as NumPy or libraries\n",
    "built on top of optimized C or Fortran implementations. NumPy, for example, is a popular library for numerical \n",
    "computing in Python and provides highly efficient matrix multiplication operations, benefiting from low-level \n",
    "optimizations and parallelization, making it much faster than plain Python implementations.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "8. In matmul, why is ac==br?\n",
    "\n",
    "Ans-\n",
    "\n",
    "\n",
    "In the context of matrix multiplication, when performing the operation `C = A @ B` in Python (or `C = torch.matmul(A, B)` \n",
    "in PyTorch), the matrices A and B must satisfy a specific condition for the multiplication to be valid. \n",
    "This condition is that the number of columns in matrix A must be equal to the number of rows in matrix B.\n",
    "In mathematical terms, if A is of shape (a, c) and B is of shape (b, c), the matrices can be multiplied, \n",
    "and the resulting matrix C will have the shape (a, b).\n",
    "\n",
    "In the expression `C = A @ B` or `C = torch.matmul(A, B)`, the matrices are multiplied as follows:\n",
    "\n",
    "- The element at position (i, j) in the resulting matrix C is calculated by taking the dot product of the\n",
    "i-th row of matrix A and the j-th column of matrix B.\n",
    "\n",
    "For this operation to be well-defined, the number of elements in each row of A (c) must be equal to the\n",
    "number of elements in each column of B (also c). Hence, `ac == br` ensures that the matrix multiplication\n",
    "is valid and conforms to the rules of linear algebra. If this condition is not met, the matrix multiplication\n",
    "operation will raise an error.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "9. In Jupyter Notebook, how do you measure the time taken for a single cell to execute?\n",
    "\n",
    "\n",
    "Ans-\n",
    "\n",
    "\n",
    "In Jupyter Notebook, you can measure the time taken for a single cell to execute using the `%%time` magic command\n",
    "at the beginning of the cell. When you prepend a cell with `%%time`, Jupyter Notebook will measure the execution \n",
    "time of the entire cell's code block.\n",
    "\n",
    "Here's how you can use `%%time` to measure the execution time of a single cell:\n",
    "\n",
    "```python\n",
    "%%time\n",
    "# Your code here\n",
    "# ...\n",
    "```\n",
    "\n",
    "When you run this cell, Jupyter Notebook will display the output including the time taken for the cell to execute.\n",
    "It provides information such as CPU time, wall time, and other details about the cell execution.\n",
    "\n",
    "Remember that `%%time` measures the time for the entire cell to execute, including all the code within that cell. \n",
    "If you want to measure the time for a specific portion of the code, you can use the `time` module in Python and \n",
    "its `time()` function to record the start and end times and calculate the duration.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "10. What is elementwise arithmetic?\n",
    "\n",
    "\n",
    "Ans-\n",
    "\n",
    "\n",
    "Elementwise arithmetic, also known as elementwise operations or elementwise calculations, refers to performing\n",
    "arithmetic operations separately on each element of a data structure, such as a vector, matrix, or tensor. \n",
    "In the context of deep learning and numerical computing, elementwise arithmetic involves applying arithmetic\n",
    "operations (addition, subtraction, multiplication, division, etc.) to corresponding elements of two or more \n",
    "arrays (vectors, matrices, or tensors) to produce a new array of the same shape.\n",
    "\n",
    "For example, consider two matrices \\( A \\) and \\( B \\) of the same shape:\n",
    "\n",
    "\\[ A = \\begin{bmatrix}\n",
    "a_{11} & a_{12} \\\\\n",
    "a_{21} & a_{22} \\\\\n",
    "\\end{bmatrix} \\]\n",
    "\n",
    "\\[ B = \\begin{bmatrix}\n",
    "b_{11} & b_{12} \\\\\n",
    "b_{21} & b_{22} \\\\\n",
    "\\end{bmatrix} \\]\n",
    "\n",
    "Elementwise addition of \\( A \\) and \\( B \\) (denoted as \\( A + B \\)) results in the following matrix:\n",
    "\n",
    "\\[ A + B = \\begin{bmatrix}\n",
    "a_{11} + b_{11} & a_{12} + b_{12} \\\\\n",
    "a_{21} + b_{21} & a_{22} + b_{22} \\\\\n",
    "\\end{bmatrix} \\]\n",
    "\n",
    "Similarly, elementwise subtraction, multiplication, and division can be performed in the same manner.\n",
    "\n",
    "In the context of programming and libraries like NumPy or PyTorch, elementwise operations are efficiently \n",
    "implemented and are a fundamental building block for various numerical computations in deep learning algorithms.\n",
    "These operations are highly parallelizable and are optimized for modern hardware, making them essential for \n",
    "efficient implementation of neural networks and related algorithms.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "11. Write the PyTorch code to test whether every element of a is greater than the\n",
    "corresponding element of b.\n",
    "\n",
    "\n",
    "Ans-\n",
    "\n",
    "\n",
    "You can use PyTorch to test whether every element of one tensor is greater than the corresponding element,\n",
    "of another tensor. Here's an example of how to do this:\n",
    "\n",
    "```python\n",
    "import torch\n",
    "\n",
    "# Create two tensors 'a' and 'b'\n",
    "a = torch.tensor([2, 4, 6, 8])\n",
    "b = torch.tensor([1, 3, 5, 7])\n",
    "\n",
    "# Test if every element of 'a' is greater than 'b'\n",
    "result = (a > b).all()\n",
    "\n",
    "# Print the result\n",
    "print(\"Are all elements of 'a' greater than 'b'?\")\n",
    "print(result.item())  # Use .item() to convert the result to a Python boolean\n",
    "```\n",
    "\n",
    "In this code, we create two tensors 'a' and 'b' and then use the `(a > b).all()` expression to check if every,\n",
    "element of 'a' is greater than the corresponding element of 'b'. The `.all()` function returns `True` if all,\n",
    "elements in the resulting boolean tensor are `True`, indicating that every element in 'a' is indeed greater,\n",
    "than the corresponding element in 'b.\n",
    "\n",
    "You can modify the values in the 'a' and 'b' tensors to test different cases.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "12. What is a rank-0 tensor? How do you convert it to a plain Python data type?\n",
    "\n",
    "\n",
    "Ans-\n",
    "\n",
    "\n",
    "A rank-0 tensor, also known as a scalar, is a tensor with zero dimensions. In other words, it represents a single value,\n",
    "such as a number or a constant. Unlike higher-dimensional tensors (vectors, matrices, etc.), a rank-0 tensor has no,\n",
    "axes or dimensions, making it the simplest form of tensor.\n",
    "\n",
    "In PyTorch, you can create a rank-0 tensor (scalar) using the `torch.tensor()` function without passing any ,\n",
    "iterable object, like this:\n",
    "\n",
    "```python\n",
    "import torch\n",
    "\n",
    "# Create a rank-0 tensor (scalar)\n",
    "scalar_tensor = torch.tensor(42)  # Example value: 42\n",
    "\n",
    "# Check the tensor's shape (it will be an empty tuple for a scalar)\n",
    "print(\"Shape of the scalar tensor:\", scalar_tensor.shape)\n",
    "```\n",
    "\n",
    "To convert a rank-0 tensor (scalar) to a plain Python data type, you can use the `.item()` method. This method extracts,\n",
    "the scalar value from the tensor and returns it as a native Python data type. Here's an example:\n",
    "\n",
    "```python\n",
    "# Convert the rank-0 tensor to a plain Python data type\n",
    "scalar_value = scalar_tensor.item()\n",
    "\n",
    "# Check the data type of the converted value\n",
    "print(\"Converted scalar value to Python data type:\", scalar_value)\n",
    "```\n",
    "\n",
    "In this example, `scalar_tensor.item()` is used to extract the scalar value (42 in this case) from the rank-0 tensor,\n",
    "and store it in the variable `scalar_value`. The resulting `scalar_value` variable is a plain Python integer.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "13. How does elementwise arithmetic help us speed up matmul?\n",
    "\n",
    "\n",
    "\n",
    "Ans-\n",
    "\n",
    "\n",
    "14. What are the broadcasting rules?\n",
    "\n",
    "\n",
    "Ans-\n",
    "\n",
    "\n",
    "In deep learning and numerical computing, broadcasting is a technique used to perform elementwise operations\n",
    "on arrays of different shapes without the need for explicit tiling or copying of data. When performing\n",
    "elementwise operations, the smaller array is \"broadcast\" over the larger array so that they have compatible shapes. \n",
    "The broadcasting rules determine how arrays with different shapes can be broadcast together.\n",
    "\n",
    "Here are the broadcasting rules in NumPy and similar libraries:\n",
    "\n",
    "1. **Dimensions Compatibility:** Two dimensions are compatible for broadcasting if they are equal or one of them is 1.\n",
    "    If a dimension is missing in one of the input arrays, it is assumed to be 1 in that dimension.\n",
    "\n",
    "   For example, if you have a 2D array A with shape (3, 1) and another 1D array B with shape (3,), broadcasting can\n",
    "be performed because the second dimension of A is 1, which is compatible with the corresponding dimension of B.\n",
    "\n",
    "2. **Size Compatibility:** Arrays with smaller dimensions are padded with ones on their left side to match the number\n",
    "    of dimensions of the larger array.\n",
    "\n",
    "   For example, if you have a 3D array A with shape (1, 2, 3) and another 2D array B with shape (2, 3), broadcasting\n",
    "can be performed because array A can be broadcasted to shape (1, 2, 3) to match the shape of B.\n",
    "\n",
    "3. **Broadcasting Iteration:** When performing operations, the dimensions are iterated from right to left. \n",
    "    Dimensions are aligned, and the operation is carried out elementwise.\n",
    "\n",
    "Here's an example to illustrate the broadcasting rules:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "# Example arrays\n",
    "A = np.array([[1], [2], [3]])  # Shape (3, 1)\n",
    "B = np.array([1, 2, 3])        # Shape (3,)\n",
    "\n",
    "# Broadcasting A and B to perform elementwise addition\n",
    "result = A + B\n",
    "\n",
    "# Resulting array after broadcasting\n",
    "# [[1, 1, 1],\n",
    "#  [2, 2, 2],\n",
    "#  [3, 3, 3]]\n",
    "\n",
    "print(result)\n",
    "```\n",
    "\n",
    "In this example, array A is broadcasted to shape (3, 3) to match the shape of array B for elementwise addition.\n",
    "Broadcasting allows these operations to be performed without the need for explicit replication of data.\n",
    "Broadcasting greatly simplifies operations and makes code more concise and readable.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "15. What is expand_as? Show an example of how it can be used to match the results of\n",
    "broadcasting.\n",
    "\n",
    "\n",
    "\n",
    "Ans-\n",
    "\n",
    "In PyTorch, `expand_as` is a method that allows you to expand the dimensions of a tensor to match the shape,\n",
    "of another tensor. This can be particularly useful when you want to perform elementwise operations on tensors\n",
    "with different shapes and you need to ensure that they have compatible dimensions through broadcasting.\n",
    "\n",
    "Here's an example of how `expand_as` can be used to match the results of broadcasting:\n",
    "\n",
    "```python\n",
    "import torch\n",
    "\n",
    "# Example tensors\n",
    "A = torch.tensor([[1], [2], [3]])  # Shape (3, 1)\n",
    "B = torch.tensor([1, 2, 3])        # Shape (3,)\n",
    "\n",
    "# Use expand_as to expand the dimensions of tensor A to match the shape of B\n",
    "expanded_A = A.expand_as(B.reshape(-1, 1))\n",
    "\n",
    "# Perform elementwise addition\n",
    "result = expanded_A + B\n",
    "\n",
    "print(\"Expanded A:\")\n",
    "print(expanded_A)\n",
    "print(\"Result after elementwise addition:\")\n",
    "print(result)\n",
    "```\n",
    "\n",
    "In this example, `B.reshape(-1, 1)` reshapes tensor B into a column vector of shape (3, 1). \n",
    "`A.expand_as(B.reshape(-1, 1))` then expands the dimensions of tensor A to match the shape of this reshaped B.\n",
    "Finally, elementwise addition is performed, resulting in a tensor where broadcasting is achieved through the \n",
    "use of `expand_as`. The resulting `expanded_A` matches the shape of `B` and allows elementwise addition without\n",
    "broadcasting issues.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
