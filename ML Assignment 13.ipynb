{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf968778",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. Provide an example of the concepts of Prior, Posterior, and Likelihood.\n",
    "\n",
    "\n",
    "Ans- \n",
    "\n",
    "Certainly! Let's consider a classic example in the context of medical diagnosis.\n",
    "\n",
    "Imagine a patient visits a doctor with symptoms that could be indicative of a rare disease, let's call it Disease X. \n",
    "The doctor has some prior knowledge about the prevalence of Disease X in the general population, say 1 in 10,000 people. \n",
    "This prior probability, denoted as P(Disease X), represents the probability of the patient having Disease X before taking\n",
    "any symptoms into account.\n",
    "\n",
    "Now, the doctor conducts some tests on the patient. Based on these test results, the doctor calculates the likelihood of\n",
    "observing these results given that the patient has Disease X. This likelihood, denoted as P(Test Results | Disease X), \n",
    "represents how likely the observed test results are if the patient truly has Disease X.\n",
    "\n",
    "Additionally, the doctor needs to consider the probability of observing the given test results irrespective of whether\n",
    "the patient has Disease X or not. This is called the marginal likelihood or evidence, denoted as P(Test Results). \n",
    "It represents the overall probability of obtaining the test results, regardless of the presence or absence of Disease X.\n",
    "\n",
    "Using Bayes' theorem, the doctor can calculate the posterior probability of the patient having Disease X given the \n",
    "observed test results. The posterior probability, denoted as P(Disease X | Test Results), represents the updated \n",
    "probability of the patient having Disease X after taking the test results into account. Bayes' theorem states:\n",
    "\n",
    "\\[ P(Disease X | Test Results) = \\frac{P(Test Results | Disease X) \\times P(Disease X)}{P(Test Results)} \\]\n",
    "\n",
    "In this example:\n",
    "\n",
    "- **Prior Probability (Prior)**: \\(P(Disease X)\\) - The doctor's initial belief about the probability of the patient\n",
    "    having Disease X based on general population data.\n",
    "- **Likelihood (Likelihood)**: \\(P(Test Results | Disease X)\\) - The probability of observing the given test results\n",
    "    if the patient truly has Disease X.\n",
    "- **Posterior Probability (Posterior)**: \\(P(Disease X | Test Results)\\) - The updated probability of the patient \n",
    "    having Disease X after considering the test results.\n",
    "- **Marginal Likelihood (Evidence)**: \\(P(Test Results)\\) - The overall probability of obtaining the test results,\n",
    "    calculated by summing the probabilities of getting those results given both the presence and absence of Disease X.\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "2. What role does Bayes&#39; theorem play in the concept learning principle?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Ans-\n",
    "\n",
    "\n",
    "Bayes' theorem plays a fundamental role in the concept learning principle, especially in the context of probabilistic \n",
    "learning and making inferences based on observed data. In the framework of machine learning and statistics,\n",
    "concept learning involves learning to classify objects or examples into different categories or concepts based\n",
    "on their features or attributes.\n",
    "\n",
    "Bayes' theorem provides a principled way to update beliefs or probabilities about hypotheses (concepts) given \n",
    "new evidence (data). In the context of concept learning, Bayes' theorem allows for the iterative refinement of\n",
    "hypotheses as new data becomes available. Here's how it fits into the concept learning principle:\n",
    "\n",
    "1. **Initial Beliefs (Prior)**: Before observing any data, there are initial beliefs about the likelihood of\n",
    "    different hypotheses or concepts being true. These beliefs are represented by the prior probabilities.\n",
    "\n",
    "2. **Observing Data (Likelihood)**: When new data (evidence) is observed, Bayes' theorem calculates the likelihood \n",
    "    of observing this data given each hypothesis. This likelihood represents how well the hypotheses explain the observed data.\n",
    "    \n",
    "\n",
    "3. **Updating Beliefs (Posterior)**: Bayes' theorem combines the prior beliefs and the likelihood of the observed data to \n",
    "    calculate the posterior probabilities of the hypotheses. The posterior probabilities represent the updated beliefs\n",
    "    about the hypotheses after taking the observed data into account.\n",
    "\n",
    "4. **Iterative Learning**: As more data becomes available, Bayes' theorem can be applied iteratively to update the \n",
    "    beliefs and refine the hypotheses. This iterative process allows for continuous learning and adaptation as new \n",
    "    evidence accumulates.\n",
    "\n",
    "In the context of machine learning algorithms, Bayesian methods, including Bayesian networks and probabilistic\n",
    "graphical models, leverage Bayes' theorem to model uncertainty, make predictions, and infer relationships between\n",
    "variables. By incorporating prior knowledge and updating beliefs based on observed data, these models can learn \n",
    "complex patterns and make informed decisions, making them valuable tools in the field of concept learning.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "3. Offer an example of how the Nave Bayes classifier is used in real life.\n",
    "\n",
    "\n",
    "\n",
    "Ans-\n",
    "\n",
    "One real-life application of the Naive Bayes classifier is in email spam filtering. Spam email detection is a common \n",
    "problem faced by email service providers and users. The Naive Bayes classifier can be used effectively to filter out\n",
    "spam emails from legitimate ones.\n",
    "\n",
    "Here's how it works:\n",
    "\n",
    "### Spam Email Filtering with Naive Bayes Classifier:\n",
    "\n",
    "1. **Data Collection**:\n",
    "   - Collect a dataset of emails that are labeled as either spam or non-spam (ham). This dataset is used to train the\n",
    "Naive Bayes classifier.\n",
    "\n",
    "2. **Feature Extraction**:\n",
    "   - Extract relevant features from the email content. These features could include words, phrases, or other \n",
    "characteristics that are indicative of spam or non-spam emails. For example, the presence of certain keywords,\n",
    "the frequency of specific terms, or the sender's email address.\n",
    "\n",
    "3. **Training the Naive Bayes Classifier**:\n",
    "   - Using the labeled dataset, train the Naive Bayes classifier by calculating the probabilities of different\n",
    "words or features occurring in spam and non-spam emails. The classifier assumes that the features are conditionally\n",
    "independent given the class (spam or non-spam), which is why \n",
    "it's called \"naive.\" Despite this simplifying assumption, Naive Bayes often performs surprisingly well in practice\n",
    "for text classification tasks like spam filtering.\n",
    "\n",
    "4. **Spam Detection**:\n",
    "   - When a new email arrives, the Naive Bayes classifier calculates the probability of the email being spam or \n",
    "non-spam based on the features present in the email. It computes the likelihood of observing those features given \n",
    "the class (spam or non-spam) and combines it with prior probabilities.\n",
    "\n",
    "5. **Classification**:\n",
    "   - The email is classified as spam or non-spam based on which class (spam or non-spam) has the higher probability\n",
    "according to the Naive Bayes classifier. If the probability of being spam is higher than a certain threshold, \n",
    "the email is classified as spam and moved to the spam folder.\n",
    "\n",
    "6. **Iterative Learning**:\n",
    "   - As more labeled data becomes available, the classifier can be retrained to improve its accuracy and adapt to \n",
    "new patterns in spam emails.\n",
    "\n",
    "Naive Bayes classifiers are popular for email spam filtering due to their simplicity, speed, and surprisingly good \n",
    "performance, especially when dealing with large volumes of email data. They are widely used by email service providers \n",
    "to automatically filter out unwanted spam emails from users' inboxes.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "4. Can the Nave Bayes classifier be used on continuous numeric data? If so, how can you go about\n",
    "doing it?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Ans-\n",
    "\n",
    "\n",
    "Yes, the Naive Bayes classifier can be used with continuous numeric data. When dealing with continuous data, \n",
    "you need to make an assumption about the distribution of the data within each class (e.g., normal distribution) \n",
    "and then use probability density functions to calculate the likelihoods. One common approach is to use the Gaussian\n",
    "Naive Bayes classifier, which assumes that the continuous features within each class are normally distributed.\n",
    "\n",
    "Here's how you can use the Gaussian Naive Bayes classifier with continuous numeric data:\n",
    "\n",
    "### Gaussian Naive Bayes Classifier for Continuous Numeric Data:\n",
    "\n",
    "1. **Data Preparation**:\n",
    "   - Gather a dataset with continuous numeric features and corresponding class labels. Ensure the data is divided \n",
    "into classes (categories) you want to classify.\n",
    "\n",
    "2. **Assumption of Normality**:\n",
    "   - Assume that the continuous features within each class are normally distributed. This assumption is important \n",
    "for the Gaussian Naive Bayes classifier.\n",
    "\n",
    "3. **Calculate Mean and Standard Deviation**:\n",
    "   - For each class, calculate the mean and standard deviation of each feature. These parameters will be used to \n",
    "define the normal distribution for each class.\n",
    "\n",
    "4. **Probability Density Function (PDF)**:\n",
    "   - Use the mean and standard deviation to calculate the probability density function (PDF) for each feature \n",
    "within each class. The PDF represents the likelihood of observing a specific value given the class.\n",
    "\n",
    "   - For a feature x in class C, the PDF can be calculated using the formula:\n",
    "     \\[ P(x|C) = \\frac{1}{\\sqrt{2\\pi \\sigma^2}} e^{-\\frac{(x - \\mu)^2}{2\\sigma^2}} \\]\n",
    "     where \\( \\mu \\) is the mean and \\( \\sigma \\) is the standard deviation of the feature in class C.\n",
    "\n",
    "5. **Prior Probability**:\n",
    "   - Calculate the prior probability of each class, representing the likelihood of each class occurring without \n",
    "considering any features.\n",
    "\n",
    "6. **Classification**:\n",
    "   - When classifying a new data point with continuous features, calculate the likelihood of the features given each\n",
    "class using the PDFs. Multiply the likelihoods of all features together and multiply the result by the prior probability \n",
    "of the class. The class with the highest probability is the predicted class for the new data point.\n",
    "\n",
    "   - Mathematically, for a class C, the posterior probability can be calculated as:\n",
    "     \\[ P(C|x_1, x_2, ..., x_n) \\propto P(C) \\times P(x_1|C) \\times P(x_2|C) \\times ... \\times P(x_n|C) \\]\n",
    "\n",
    "   - Compare the posterior probabilities for each class and assign the class with the highest probability to the new \n",
    "data point.\n",
    "\n",
    "By making the assumption of normality and using the Gaussian Naive Bayes approach, the classifier can handle continuous\n",
    "numeric data for classification tasks.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "5. What are Bayesian Belief Networks, and how do they work? What are their applications? Are they\n",
    "capable of resolving a wide range of issues?\n",
    "\n",
    "\n",
    "\n",
    "Ans-\n",
    "\n",
    "\n",
    "Bayesian Belief Networks (BBNs), also known as Bayesian Networks or Probabilistic Graphical Models, are graphical models\n",
    "that represent probabilistic relationships among a set of variables. BBNs are based on the principles of probability\n",
    "theory and graph theory and are used to model uncertain knowledge and make predictions or inferences under uncertainty.\n",
    "\n",
    "### How Bayesian Belief Networks Work:\n",
    "\n",
    "1. **Graphical Representation**:\n",
    "   - BBNs consist of nodes (representing random variables) and directed edges (representing probabilistic dependencies)\n",
    "between nodes. The nodes can represent observable variables, hidden variables, or hypotheses, while the edges indicate\n",
    "the probabilistic relationships between them.\n",
    "\n",
    "2. **Conditional Probability Tables (CPTs)**:\n",
    "   - Each node in a BBN has an associated Conditional Probability Table (CPT) that quantifies the probabilistic \n",
    "relationship between that node and its parent nodes. The CPT specifies the probability distribution of a node given \n",
    "its parent nodes' states.\n",
    "\n",
    "3. **Probabilistic Inference**:\n",
    "   - BBNs allow for probabilistic inference, enabling the calculation of probabilities of specific variables given\n",
    "observed evidence. Inference in BBNs involves updating the probabilities of nodes based on observed evidence, \n",
    "using the graph structure and the conditional probabilities specified in the CPTs.\n",
    "\n",
    "### Applications of Bayesian Belief Networks:\n",
    "\n",
    "1. **Diagnosis and Risk Assessment**:\n",
    "   - BBNs are used in medical diagnosis to model symptoms, diseases, and risk factors, allowing doctors to assess\n",
    "the likelihood of different diseases based on observed symptoms and test results.\n",
    "\n",
    "2. **Decision Support Systems**:\n",
    "   - BBNs are employed in decision support systems for risk analysis, helping businesses and organizations make\n",
    "decisions under uncertainty by modeling various factors and their interdependencies.\n",
    "\n",
    "3. **Natural Language Processing**:\n",
    "   - BBNs are used in natural language processing tasks, such as part-of-speech tagging and machine translation, \n",
    "to model the probabilistic relationships between words and linguistic structures.\n",
    "\n",
    "4. **Fraud Detection**:\n",
    "   - BBNs can be applied in fraud detection systems to model patterns of fraudulent behavior and detect anomalies\n",
    "in financial transactions or other types of data.\n",
    "\n",
    "5. **Environmental Modeling**:\n",
    "   - BBNs are used in environmental modeling to assess the impact of different variables (such as pollution sources\n",
    "     and weather conditions) on environmental systems.\n",
    "\n",
    "6. **Predictive Maintenance**:\n",
    "   - BBNs are applied in predictive maintenance scenarios, where they model relationships between equipment conditions, \n",
    "     usage patterns, and maintenance actions to predict when equipment is likely to fail.\n",
    "\n",
    "### Limitations and Considerations:\n",
    "\n",
    "While BBNs are powerful tools for modeling and reasoning under uncertainty, they do have limitations. BBNs rely on the\n",
    "assumption of conditional independence between nodes given their parents (hence the term \"Bayesian Network\").\n",
    "This independence assumption might not always hold in real-world scenarios, leading to potential inaccuracies in the model.\n",
    "\n",
    "Additionally, the complexity of BBNs can increase significantly as more variables and dependencies are added, making \n",
    "them computationally intensive and challenging to design and maintain.\n",
    "\n",
    "In summary, Bayesian Belief Networks are versatile tools widely used in various fields to model uncertain knowledge and\n",
    "make informed decisions. While they are capable of resolving a wide range of issues, careful consideration of the\n",
    "model's assumptions and limitations is necessary to ensure accurate and reliable results.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "6. Passengers are checked in an airport screening system to see if there is an intruder. Let I be the\n",
    "random variable that indicates whether someone is an intruder I = 1) or not I = 0), and A be the\n",
    "variable that indicates alarm I = 0). If an intruder is detected with probability P(A = 1|I = 1) = 0.98\n",
    "and a non-intruder is detected with probability P(A = 1|I = 0) = 0.001, an alarm will be triggered,\n",
    "implying the error factor. The likelihood of an intruder in the passenger population is P(I = 1) =\n",
    "0.00001. What are the chances that an alarm would be triggered when an individual is actually an\n",
    "intruder?\n",
    "\n",
    "\n",
    "\n",
    "Ans-\n",
    "\n",
    "\n",
    "To calculate the probability that an alarm is triggered when an individual is actually an intruder (P(A=1|I=1)), \n",
    "we can use Bayes' theorem. Bayes' theorem allows us to update our belief about the probability of an event based \n",
    "on new evidence. In this case, the evidence is the alarm being triggered (A=1) and the event of interest is the \n",
    "individual being an intruder (I=1).\n",
    "\n",
    "Bayes' theorem is given by:\n",
    "\n",
    "\\[ P(I=1|A=1) = \\frac{P(A=1|I=1) \\times P(I=1)}{P(A=1)} \\]\n",
    "\n",
    "To calculate \\(P(A=1)\\), we need to consider all possible scenarios in which an alarm can be triggered, whether\n",
    "there is an intruder or not. This can be expressed as:\n",
    "\n",
    "\\[ P(A=1) = P(A=1|I=1) \\times P(I=1) + P(A=1|I=0) \\times P(I=0) \\]\n",
    "\n",
    "Given the information provided:\n",
    "\n",
    "- \\(P(A=1|I=1) = 0.98\\)\n",
    "- \\(P(A=1|I=0) = 0.001\\)\n",
    "- \\(P(I=1) = 0.00001\\)\n",
    "- \\(P(I=0) = 1 - P(I=1) = 1 - 0.00001 = 0.99999\\)\n",
    "\n",
    "Now, plug these values into the equation for \\(P(A=1)\\):\n",
    "\n",
    "\\[ P(A=1) = 0.98 \\times 0.00001 + 0.001 \\times 0.99999 \\]\n",
    "\n",
    "Calculate \\(P(A=1)\\), and then use Bayes' theorem to find \\(P(I=1|A=1)\\):\n",
    "\n",
    "\\[ P(I=1|A=1) = \\frac{0.98 \\times 0.00001}{P(A=1)} \\]\n",
    "\n",
    "This calculation will give you the probability that an alarm would be triggered when an individual is actually an intruder.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "7. An antibiotic resistance test (random variable T) has 1% false positives (i.e., 1% of those who are\n",
    "not immune to an antibiotic display a positive result in the test) and 5% false negatives (i.e., 1% of\n",
    "those who are not resistant to an antibiotic show a positive result in the test) (i.e. 5 percent of those\n",
    "actually resistant to an antibiotic test negative). Assume that 2% of those who were screened were\n",
    "antibiotic-resistant. Calculate the likelihood that a person who tests positive is actually immune\n",
    "(random variable D).\n",
    "\n",
    "\n",
    "\n",
    "Ans-\n",
    "\n",
    "\n",
    "To solve this problem, we can use Bayes' theorem. Let's define the events:\n",
    "\n",
    "- \\( D = 1 \\) if a person is immune (has antibiotic resistance).\n",
    "- \\( T = 1 \\) if the antibiotic resistance test is positive.\n",
    "\n",
    "We are interested in finding \\( P(D=1|T=1) \\), the probability that a person is immune given that the test is positive.\n",
    "\n",
    "We are given the following probabilities:\n",
    "\n",
    "- False positive rate: \\( P(T=1|D=0) = 0.01 \\) (1% false positives)\n",
    "- False negative rate: \\( P(T=0|D=1) = 0.05 \\) (5% false negatives)\n",
    "- Prevalence of antibiotic resistance: \\( P(D=1) = 0.02 \\) (2% of the population is resistant)\n",
    "\n",
    "Using Bayes' theorem, the probability that a person is immune given that the test is positive can be calculated as follows:\n",
    "\n",
    "\\[ P(D=1|T=1) = \\frac{P(T=1|D=1) \\times P(D=1)}{P(T=1)} \\]\n",
    "\n",
    "The total probability of testing positive (\\( P(T=1) \\)) can be calculated using the law of total probability:\n",
    "\n",
    "\\[ P(T=1) = P(T=1|D=1) \\times P(D=1) + P(T=1|D=0) \\times P(D=0) \\]\n",
    "\n",
    "Substituting the given probabilities:\n",
    "\n",
    "\\[ P(T=1) = 0.95 \\times 0.02 + 0.01 \\times 0.98 \\]\n",
    "\n",
    "\\[ P(T=1) = 0.0392 + 0.0098 \\]\n",
    "\n",
    "\\[ P(T=1) = 0.049 \\]\n",
    "\n",
    "Now, substitute this value back into the original equation for \\( P(D=1|T=1) \\):\n",
    "\n",
    "\\[ P(D=1|T=1) = \\frac{0.95 \\times 0.02}{0.049} \\]\n",
    "\n",
    "\\[ P(D=1|T=1) = \\frac{0.019}{0.049} \\]\n",
    "\n",
    "\\[ P(D=1|T=1) â‰ˆ 0.3878 \\]\n",
    "\n",
    "So, the likelihood that a person who tests positive is actually immune (antibiotic-resistant) is approximately 38.78%.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "8. In order to prepare for the test, a student knows that there will be one question in the exam that\n",
    "is either form A, B, or C. The chances of getting an A, B, or C on the exam are 30 percent, 20%, and\n",
    "50 percent, respectively. During the planning, the student solved 9 of 10 type A problems, 2 of 10\n",
    "type B problems, and 6 of 10 type C problems.\n",
    "\n",
    "1. What is the likelihood that the student can solve the exam problem?\n",
    "\n",
    "2. Given the student&#39;s solution, what is the likelihood that the problem was of form A?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Ans-\n",
    "\n",
    "To solve these problems, we can use the concept of conditional probability. Let's define the events:\n",
    "\n",
    "- \\( A \\): The exam problem is of form A.\n",
    "- \\( B \\): The exam problem is of form B.\n",
    "- \\( C \\): The exam problem is of form C.\n",
    "- \\( S \\): The student can solve the exam problem.\n",
    "\n",
    "### 1. Likelihood that the student can solve the exam problem (P(S)):\n",
    "\n",
    "Using the law of total probability, the probability that the student can solve the exam problem (\\( P(S) \\)) \n",
    "can be calculated as the sum of the probabilities of the student solving the problem given each form of the exam problem, \n",
    "weighted by the probabilities of each form occurring:\n",
    "\n",
    "\\[ P(S) = P(S|A) \\times P(A) + P(S|B) \\times P(B) + P(S|C) \\times P(C) \\]\n",
    "\n",
    "Given that the student solved 9 out of 10 type A problems, 2 out of 10 type B problems, and 6 out of 10 type C problems:\n",
    "\n",
    "\\[ P(S|A) = \\frac{9}{10} \\]\n",
    "\\[ P(S|B) = \\frac{2}{10} \\]\n",
    "\\[ P(S|C) = \\frac{6}{10} \\]\n",
    "\n",
    "\\[ P(A) = 0.3 \\]\n",
    "\\[ P(B) = 0.2 \\]\n",
    "\\[ P(C) = 0.5 \\]\n",
    "\n",
    "Substituting the values:\n",
    "\n",
    "\\[ P(S) = \\left(\\frac{9}{10} \\times 0.3\\right) + \\left(\\frac{2}{10} \\times 0.2\\right) + \\left(\\frac{6}{10} \n",
    "                                                                                              \\times 0.5\\right) \\]\n",
    "\n",
    "\\[ P(S) = 0.27 + 0.04 + 0.3 \\]\n",
    "\n",
    "\\[ P(S) = 0.61 \\]\n",
    "\n",
    "So, the likelihood that the student can solve the exam problem is 61%.\n",
    "\n",
    "### 2. Likelihood that the problem was of form A given the student's solution (P(A|S)):\n",
    "\n",
    "Using Bayes' theorem, the probability that the problem was of form A given the student's solution (\\( P(A|S) \\)) can\n",
    "be calculated as:\n",
    "\n",
    "\\[ P(A|S) = \\frac{P(S|A) \\times P(A)}{P(S)} \\]\n",
    "\n",
    "Using the previously calculated values:\n",
    "\n",
    "\\[ P(A|S) = \\frac{\\left(\\frac{9}{10}\\right) \\times 0.3}{0.61} \\]\n",
    "\n",
    "\\[ P(A|S) = \\frac{0.27}{0.61} \\]\n",
    "\n",
    "\\[ P(A|S) \\approx 0.4426 \\]\n",
    "\n",
    "So, given the student's solution, the likelihood that the problem was of form A is approximately 44.26%.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "9. A bank installs a CCTV system to track and photograph incoming customers. Despite the constant\n",
    "influx of customers, we divide the timeline into 5 minute bins. There may be a customer coming into\n",
    "the bank with a 5% chance in each 5-minute time period, or there may be no customer (again, for\n",
    "simplicity, we assume that either there is 1 customer or none, not the case of multiple customers). If\n",
    "\n",
    "there is a client, the CCTV will detect them with a 99 percent probability. If there is no customer, the\n",
    "camera can take a false photograph with a 10% chance of detecting movement from other objects.\n",
    "\n",
    "1. How many customers come into the bank on a daily basis (10 hours)?\n",
    "\n",
    "2. On a daily basis, how many fake photographs (photographs taken when there is no\n",
    "customer) and how many missed photographs (photographs taken when there is a customer) are\n",
    "there?\n",
    "\n",
    "3. Explain likelihood that there is a customer if there is a photograph?\n",
    "\n",
    "\n",
    "\n",
    "Ans-\n",
    "\n",
    "Let's analyze the given probabilities and conditions to answer each of the questions:\n",
    "\n",
    "### 1. How many customers come into the bank on a daily basis (10 hours)?\n",
    "\n",
    "In 10 hours, there are \\(10 \\times 60 = 600\\) minutes. Each 5-minute interval has a 5% chance of having a customer.\n",
    "Therefore, the expected number of customers in a 5-minute interval is \\(0.05 \\times 1 = 0.05\\). \n",
    "\n",
    "To calculate the expected number of customers in 10 hours, divide the total time by the duration of one interval:\n",
    "\n",
    "\\[ \\text{Expected customers in 10 hours} = 0.05 \\times \\frac{600}{5} = 6 \\]\n",
    "\n",
    "So, on average, 6 customers come into the bank on a daily basis.\n",
    "\n",
    "### 2. On a daily basis, how many fake photographs and how many missed photographs are there?\n",
    "\n",
    "#### Fake Photographs:\n",
    "The camera can take a false photograph with a 10% chance when there is no customer. In each 5-minute interval,\n",
    "if there is no customer, the probability of taking a fake photograph is 10% or 0.1. The total number of 5-minute \n",
    "intervals in 10 hours is \\(600 / 5 = 120\\). Therefore, the expected number of fake photographs in 10 hours is:\n",
    "\n",
    "\\[ \\text{Expected fake photographs} = 0.1 \\times 0.05 \\times 120 = 0.6 \\]\n",
    "\n",
    "So, on average, there are 0.6 fake photographs in 10 hours.\n",
    "\n",
    "#### Missed Photographs:\n",
    "If there is a customer, the CCTV will detect them with a 99% probability. So, in each 5-minute interval, \n",
    "if there is a customer, the probability of taking a missed photograph is 1% or 0.01. The total number of\n",
    "5-minute intervals in 10 hours is 120. Therefore, the expected number of missed photographs in 10 hours is:\n",
    "\n",
    "\\[ \\text{Expected missed photographs} = 0.01 \\times 0.05 \\times 120 = 0.06 \\]\n",
    "\n",
    "So, on average, there are 0.06 missed photographs in 10 hours.\n",
    "\n",
    "### 3. Explain the likelihood that there is a customer if there is a photograph?\n",
    "\n",
    "To find the likelihood that there is a customer given that there is a photograph (\\( P(\\text{Customer|Photograph}) \\)),\n",
    "we can use Bayes' theorem. \n",
    "\n",
    "Let:\n",
    "- \\( C \\): Event that there is a customer in the bank.\n",
    "- \\( P \\): Event that a photograph is taken.\n",
    "\n",
    "Using Bayes' theorem:\n",
    "\n",
    "\\[ P(\\text{C|P}) = \\frac{P(\\text{P|C}) \\times P(\\text{C})}{P(\\text{P})} \\]\n",
    "\n",
    "- \\( P(\\text{P|C}) = 0.99 \\) (probability of a photograph given there is a customer)\n",
    "- \\( P(\\text{C}) = 0.05 \\) (probability of a customer)\n",
    "- \\( P(\\text{P}) = P(\\text{P|C}) \\times P(\\text{C}) + P(\\text{P|~C}) \\times P(\\text{~C}) \\)  \n",
    "  \\(\\quad \\quad = 0.99 \\times 0.05 + 0.1 \\times 0.95 = 0.1445 \\)\n",
    "\n",
    "Substituting the values into the Bayes' theorem equation:\n",
    "\n",
    "\\[ P(\\text{C|P}) = \\frac{0.99 \\times 0.05}{0.1445} \\approx 0.3422 \\]\n",
    "\n",
    "So, the likelihood that there is a customer given that there is a photograph is approximately \\(34.22\\%\\).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "10. Create the conditional probability table associated with the node Won Toss in the Bayesian Belief\n",
    "network to represent the conditional independence assumptions of the Nave Bayes classifier for the\n",
    "match winning prediction problem in Section 6.4.4.\n",
    "\n",
    "\n",
    "\n",
    "Ans-\n",
    "\n",
    "\n",
    "In a Bayesian Belief Network (BBN) representing a Naive Bayes classifier for a match winning prediction problem,\n",
    "the node \"Won Toss\" represents whether a team won the coin toss (a binary variable: 0 for lost toss, 1 for won toss).\n",
    "In a Naive Bayes classifier, it is assumed that the features are conditionally independent given the class label \n",
    "(in this case, the outcome of the match: win or lose).\n",
    "\n",
    "Let's assume there are three features (F1, F2, and F3) used for match prediction. The conditional probability table\n",
    "(CPT) associated with the node \"Won Toss\" would look like this, assuming a binary outcome for each feature (0 or 1)\n",
    "and a binary outcome for \"Won Toss\" (0 or 1):\n",
    "\n",
    "| F1 | F2 | F3 | Won Toss=0 | Won Toss=1 |\n",
    "|----|----|----|------------|------------|\n",
    "| 0  | 0  | 0  | P(W=0|F1=0,F2=0,F3=0) | P(W=1|F1=0,F2=0,F3=0) |\n",
    "| 0  | 0  | 1  | P(W=0|F1=0,F2=0,F3=1) | P(W=1|F1=0,F2=0,F3=1) |\n",
    "| 0  | 1  | 0  | P(W=0|F1=0,F2=1,F3=0) | P(W=1|F1=0,F2=1,F3=0) |\n",
    "| 0  | 1  | 1  | P(W=0|F1=0,F2=1,F3=1) | P(W=1|F1=0,F2=1,F3=1) |\n",
    "| 1  | 0  | 0  | P(W=0|F1=1,F2=0,F3=0) | P(W=1|F1=1,F2=0,F3=0) |\n",
    "| 1  | 0  | 1  | P(W=0|F1=1,F2=0,F3=1) | P(W=1|F1=1,F2=0,F3=1) |\n",
    "| 1  | 1  | 0  | P(W=0|F1=1,F2=1,F3=0) | P(W=1|F1=1,F2=1,F3=0) |\n",
    "| 1  | 1  | 1  | P(W=0|F1=1,F2=1,F3=1) | P(W=1|F1=1,F2=1,F3=1) |\n",
    "\n",
    "In this table, \"W\" represents the outcome of the match (0 for lose, 1 for win), and F1, F2, and F3 represent the \n",
    "values of the features. The probabilities in the table need to be estimated from the training data, reflecting the\n",
    "likelihood of winning or losing the match given the specific combination of feature values and the outcome of the coin toss.\n",
    "\n",
    "Please note that the specific probabilities in the table need to be calculated based on the training data, as they\n",
    "represent the conditional probabilities of winning or losing the match given the features and the outcome of the coin toss.\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
